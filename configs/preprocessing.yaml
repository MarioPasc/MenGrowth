preprocessing:
  data_harmonization:
    enabled: true

    # Selection
    patient_selector: "single"        # "single" | "all"
    patient_id: "MenGrowth-0015"      # used only if patient_selector == "single"

    # I/O mode
    mode: "test"                       # "test" | "pipeline"
    dataset_root: "/media/mpascual/PortableSSD/Meningiomas/MenGrowth/raw/MenGrowth-2025"
    output_root: "/media/mpascual/PortableSSD/Meningiomas/MenGrowth/preprocessed/MenGrowth-2025"     # used in test mode
    preprocessing_artifacts_path: "/media/mpascual/PortableSSD/Meningiomas/MenGrowth/preprocessed/artifacts"  # intermediate artifacts
    viz_root: "/media/mpascual/PortableSSD/Meningiomas/MenGrowth/preprocessed/viz"              # quick-looks for both modes
    overwrite: true                                                   # guard rails

    # Modalities to include (if present in a study directory)
    modalities: ["t1c", "t1n", "t2w", "t2f"]

    step0_data_harmonization:
        save_visualization: true # Save this step's visualization for the method used

        # Orientation
        reorient_to: "RAS"                 # "RAS" | "LPS"

        # Background zeroing (conservative)
        background_zeroing:
          method: null # "border_connected_percentile" | "self_head_mask" | null

          # if method == "border_connected_percentile"
          percentile_low: 2              # [0.1-2.0], conservative default
          gaussian_sigma: 0.5            # smoothing before thresholding (vox)
          min_comp_voxels: 500           # ignore tiny components

          # if method == "self_head_mask" - Fallback control
          auto_fallback: true            # Use simple fallback if SELF fails
          fallback_threshold: 0.05       # Min coverage (5%) for SELF before fallback
          fallback_method: "otsu"        # Fallback method: "otsu" | "percentile" | "zero"
          fallback_percentile: 10.0      # Percentile threshold for fallback (if method="percentile")
          fill_value: 0.0                # Value to set for background voxels

          air_p_low: 2.0                 # Percentile threshold for seeding air [0.0-100.0]
          air_p_high: 20.0               # Percentile threshold for flood-fill through dark voxels
          air_p_global: 0.2              # Global percentile for darkest voxels as fallback seeds
          erode_vox: 1                   # Erosion iterations on head seed (0=conservative)
          close_iters: 2                 # Iterations for final morphological smoothing
          connectivity: 2                # Connectivity: 1=6-conn, 2=18-conn, 3=26-conn

          # Common parameters (post-processing on air mask)
          air_border_margin: 0           # Voxels to erode the air mask (MORE conservative - shrinks air region)
          expand_air_mask: 3             # Voxels to dilate the air mask (LESS conservative - expands air region)
          # Note: Use EITHER air_border_margin OR expand_air_mask, not both > 0

    step1_bias_field_correction:
        save_visualization: true # Save visualization for bias field correction
        save_artifact: true      # Save bias field NIfTI to artifacts directory

        # Bias field correction parameters
        bias_field_correction:
          method: "n4"                     # "n4" | null (null to skip)
          shrink_factor: 4                 # Downsampling factor [1-8], higher=faster but coarser
          max_iterations: [50, 50, 50, 50] # Iterations per resolution level (4 levels)
          bias_field_fwhm: 0.15            # Gaussian smoothing FWHM [0.01-1.0], higher=smoother field
          convergence_threshold: 0.001     # Early stopping threshold (0.0-1.0)

    step2_resampling:
        save_visualization: true # Save visualization for resampling step, we must see axial, sagittal, and coronal views
        resampling:
          method: composite                   # "bspline" | "eclare" | "composite" | null (null to skip)
          
          target_voxel_size: [1.0, 1.0, 1.0]  # in mm (isotropic)

          # Normalization parameters before resampling
          normalize_method: null  # Normalization before ECLARE: null | "zscore" | "kde" | "percentile_minmax"
          # if normalize_method == "percentile_minmax"
          p1: 1.0                                 # for "percentile_minmax" normalization
          p2: 99.0                                # for "percentile_minmax" normalization 

          # BSPLINE parameters
          bspline_order: 3                    # if method == "bspline", order [0-5]

          # ECLARE Deep-Learning based super-resolution parameters
          conda_environment_eclare: "eclare"        # Name of the conda environment with ECLARE installed
          batch_size: 128                           # Batch size for ECLARE inference
          n_patches: 80000                          # Number of patches to sample for ECLARE inference
          patch_sampling: "gradient"                # Patch sampling strategy: "uniform" | "gradient" | "random"
          suffix: ""                                # Suffix to add to output filename when using ECLARE
          gpu_id: 0                                 # GPU ID(s) to use for ECLARE inference (int or list of ints, e.g., 0 or [0, 1])

          # COMPOSITE parameters
          # Composite consists of applying interpolation followed by a deep-learning based enhancement. 
          # The idea is that interpolators work better when the resolution of the image is better or closer to the target resolution.
          # Therefore, if we detect a dimension in the image that has a better resolution than the target_voxel_size, we apply the 
          # interpolator first to bring that dimension closer to the target resolution. 
          # Then, we apply the deep-learning based enhancement to reach the target resolution.
          composite_interpolator: "bspline"   # Interpolator for the first step of composite
          composite_dl_method: "eclare"       # Deep-learning method for the second step of composite
            
          # The following three arguments operate following these set of rules:
          # For a MRI volume with dimensions [dx, dy, dz] and target_voxel_size [tx, ty, tz]:
          # 1. If any dimension is lower than the corresponding target voxel size (i.e., dx < tx, dy < ty, or dz < tz),
          #    then we apply the interpolator to that dimension. 
          #    (e.g., [tx, ty, tz] = [1.0, 1.0, 1.0], [dx, dy, dz] = [0.5, 1.2, 1.5] -> apply interpolator to dx)
          # 2. If a dimension is higher than the target voxel size, but lower than the max_mm_interpolator threshold,
          #    we also apply the interpolator to that dimension.
          #    (e.g., [tx, ty, tz] = [1.0, 1.0, 1.0], [dx, dy, dz] = [1.1, 2.5, 6.0], max_mm_interpolator = 1.2 -> apply interpolator to dx)
          # 3. Dimensions between max_mm_interpolator and max_mm_dl_method are processed by deep-learning method only. 
          #    (e.g., [tx, ty, tz] = [1.0, 1.0, 1.0], [dx, dy, dz] = [1.5, 4.0, 6.0], max_mm_interpolator = 1.2, max_mm_dl_method = 5.0 -> apply dl to dx and dy)
          # 4. Dimensions higher than max_mm_dl_method are resampled using the interpolator to bring them to the resolution specified in the
          #    resample_mm_to_interpolator_if_max_mm_dl_method parameter for that dimension, then, we apply the deep-learning method to that output.
          #    (e.g., [tx, ty, tz] = [1.0, 1.0, 1.0], [dx, dy, dz] = [1.5, 6.0, 10.0], max_mm_dl_method = 5.0, resample_mm_to_interpolator_if_max_mm_dl_method = 3.0 
          #     -> resample dy and dz to 3.0 mm using the interpolator, then apply dl to dy and dz, for dx, apply dl directly)

          # Complete example:
          # Given target_voxel_size = [1.0, 1.0, 1.0], max_mm_interpolator = 1.5, max_mm_dl_method = 5.0, resample_mm_to_interpolator_if_max_mm_dl_method = 3.0
          # For an image with voxel sizes [0.8, 1.5, 6.0]:
          # - 0.8 mm  -> DL method only (rule 1)
          # - 1.5 mm  -> interpolation method only (rule 2): 1.5 <= max_mm_interpolator
          # - 6.0 mm  -> Resample to 3.0 mm with interpolator, then DL method (rule 4): 6.0 is > max_mm_dl_method 
          
          max_mm_interpolator: 1.5
          max_mm_dl_method: 5.0
          resample_mm_to_interpolator_if_max_mm_dl_method: 3.5

    step3_registration:
        save_visualization: true # Save visualization for registration step (one PNG per modality)

        # Step 3a: Intra-study multi-modal coregistration to reference
        intra_study_to_reference:
          method: "ants"                                # "ants" | null (null to skip)
          reference_modality_priority: "t1c > t1n > t2f > t2w"  # Priority order for reference selection

          # Transform parameters
          transform_type: "Rigid"                       # "Rigid" | "Affine" | "SyN"

          # Metric parameters
          metric: "Mattes"                              # "Mattes" | "MI" | "CC" | "MeanSquares" | "Demons"
          metric_bins: 32                               # Number of bins for mutual information [8-128]
          sampling_strategy: "Random"                   # "Random" | "Regular" | "None"
          sampling_percentage: 0.2                      # Percentage of voxels to sample (0.0-1.0]

          # Multi-resolution schedule
          number_of_iterations: [[1000, 500, 250]]      # Iterations per level (list of lists)
          shrink_factors: [[4, 2, 1]]                   # Downsampling factors per level (list of lists)
          smoothing_sigmas: [[2, 1, 0]]                 # Smoothing sigmas per level (list of lists)

          # Convergence parameters
          convergence_threshold: 1.0e-6                 # Convergence threshold for optimization
          convergence_window_size: 10                   # Window size for convergence detection

          # Output parameters
          write_composite_transform: true               # Write composite transform file (.h5)
          interpolation: "BSpline"                       # "Linear" | "BSpline" | "NearestNeighbor"

        # Step 3b: Register reference modality to atlas space and propagate transforms
        intra_study_to_atlas:
          method: "ants"                                # "ants" | null (null to skip atlas registration)
          atlas_path: "/media/mpascual/PortableSSD/Meningiomas/ATLAS/sri24_spm8/templates/T1.nii"       # Path to atlas template (must be set if method != null)

          # Transform parameters (can specify multiple transforms)
          transforms: ["Rigid", "Affine"]               # List of transforms to apply sequentially

          # Whether to create composite M→atlas transforms (M→ref→atlas merged into single file)
          create_composite_transforms: false            # true | false

          # Metric parameters
          metric: "Mattes"                              # "Mattes" | "MI" | "CC" | "MeanSquares" | "Demons"
          metric_bins: 32                               # Number of bins for mutual information [8-128]
          sampling_strategy: "Random"                   # "Random" | "Regular" | "None"
          sampling_percentage: 0.2                      # Percentage of voxels to sample (0.0-1.0]

          # Multi-resolution schedule (one sublist per transform)
          number_of_iterations: [[1000, 500, 250], [500, 250, 100]]  # First for Rigid, second for Affine
          shrink_factors: [[4, 2, 1], [2, 1, 1]]        # First for Rigid, second for Affine
          smoothing_sigmas: [[2, 1, 0], [1, 0, 0]]      # First for Rigid, second for Affine

          # Convergence parameters
          convergence_threshold: 1.0e-6                 # Convergence threshold for optimization
          convergence_window_size: 10                   # Window size for convergence detection

          # Output parameters
          interpolation: "BSpline"                       # "Linear" | "BSpline" | "NearestNeighbor"
    step4_skull_stripping:
        save_visualization: true      # Save visualization PNGs
        save_mask: true              # Save brain mask NIfTI to artifacts directory

        skull_stripping:
            method: "hdbet"          # "hdbet" | "synthstrip" | null (null to skip)
            fill_value: 0.0          # Value for background voxels

            # HD-BET specific parameters (used if method == "hdbet")
            hdbet_mode: "accurate"   # "fast" | "accurate"
            hdbet_device: 0          # GPU id (int) or "cpu" (str)
            hdbet_do_tta: true       # Test-time augmentation

            # SynthStrip specific parameters (used if method == "synthstrip")
            synthstrip_border: 1     # Border parameter in mm
            synthstrip_device: 0     # GPU id (int) or "cpu" (str)